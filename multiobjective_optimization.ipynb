{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LOCIE Logo](https://www.locie.univ-smb.fr/wp-content/uploads/2017/10/locie-logo-horiz.png \"LOCIE\")\n",
    "# <center> Using DEAP to do multiobjective optimization with NSGA2</center>\n",
    "\n",
    "## Version\n",
    "Version 1 on this notebook. If you have any suggestion to improve it, please let me know !\n",
    "\n",
    "## Context\n",
    "At LOCIE Lab, the project Réha-Parcs aims to apply multi-objective optimization on building stock. Bibliography tended to pick Genetic Algorithm to optimize.\n",
    "In the field of building physics, the algorithm NSGA2 is widely used because it is know as stable and results are good in term of convergence and diversity.\n",
    "\n",
    "A good implementation of NSGA2 is available in the library DEAP. This library makes possible to do complex many objective optimization and to use a lot of different algorithm pretty easily.\n",
    "\n",
    "The aim of this notebook is to provide PhD student at LOCIE with a cheatsheet to launch quickly an optimization with this algorithm with some explanation on the code. It is freely based on the example provided by the developpers of DEAP for the algorithm NSGA2 since their code is pretty short and efficient. I tried to provide more explanations and my small experience on this example here. \n",
    "\n",
    "Some prior knowledge about how NSGA-II is working is needed as this notebook is focusing on its implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "\n",
    "# If your evaluation function is external...\n",
    "# import YourEvaluationFunction as evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import stuff...an we will need constants as well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN = 50 # Number of Generation\n",
    "NBIND = 100 # Number of individual in population\n",
    "CX = 0.8 #Crossover probability\n",
    "\n",
    "NDIM = 4 # Number of dimension of the individual (=number of gene)\n",
    "\n",
    "# Bounds on walls genes\n",
    "LOW_WALLS, UP_WALLS = 0, 28\n",
    "# Bounds on windows gene\n",
    "LOW_WINDOW, UP_WINDOW = 0, 5\n",
    "\n",
    "BOUNDS = [(LOW_WALLS, UP_WALLS) for i in range(NDIM-1)] + [(LOW_WINDOW, UP_WINDOW)]\n",
    "\n",
    "BOUNDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toolboxes, creators... it's quite DEAP-specific, but powerful !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox = base.Toolbox()\n",
    "\n",
    "def init_opti():\n",
    "    \"\"\"\n",
    "    creation of the toolboxes objects that defines \n",
    "    - the type of population and the creator of individuals\n",
    "    - the difference (or ot) in the initialization of individuals\n",
    "    - the evaluation function\n",
    "    - the crossing operator\n",
    "    - the mutation operator\n",
    "    - the algorithm used to select best individuals\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    # Creation des objects liés à l'optimisation\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0, -1.0))\n",
    "    creator.create(\"Individual\", list, typecode='d', fitness=creator.FitnessMin)\n",
    "    \n",
    "    toolbox.register(\"individual\", init_ind, icls=creator.Individual, \n",
    "                     ranges=BOUNDS)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "    toolbox.register(\"evaluate\", evaluation)\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", tools.mutUniformInt, low=[x[0] for x in BOUNDS],\n",
    "                     up=[x[1] for x in BOUNDS], indpb=0.1 / NDIM)\n",
    "    toolbox.register(\"select\", tools.selNSGA2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEAP is based on toolbox: each toolbox is a component of the algorithm. Here 2 `creators` are used and the first one is important because it's creating the attribute fitness for each individual. Moreover, the tuple `weights` has as many element as the evaluation function has objectives. Here, it means that we will minimize (because `weights` are negative) 3 objectives. Should you wish to had an objective, you must had a term to this tuple otherwise it won't be taken into account (it happened to me !)\n",
    "\n",
    "Afterwards in the code are created toolboxes that choose the characteristic of the optimization such as the definition of the individual, the evaluation function, mutation and crossover operators and selection operator.\n",
    "\n",
    "NSGA2 is used for the selection tournament described by Deb. I used a classic crossing operator in one point in this example. The mutation operator in fed with the bounds for each gene of the individual otherwise it can mutate out of bounds and create an error in the evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ind(icls, ranges):\n",
    "    \"\"\"\n",
    "    Initialization of individuals: this function initializes with integer the\n",
    "    individuals with respect to the bounds given in input\n",
    "    \n",
    "    Args:\n",
    "        icls (creator): class created for Individuals\n",
    "        ranges (list): Bounds for individuals\n",
    "        \n",
    "    Returns:\n",
    "        icls (creator): Individuals created initialized with random genome\n",
    "        \n",
    "    \"\"\"\n",
    "    genome = list()\n",
    "    \n",
    "    for p in ranges:\n",
    "        genome.append(np.random.randint(*p))\n",
    "    return icls(genome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to initialize the population. The individual toolbox features an individual creator that transforms a list into an individual object: it is this *icls* function. The initialization can be done in various way depending on what is needing in input for the evaluation function. Here it need integers in the bounds predefined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the optimization: where the magic happens\n",
    "\n",
    "My main function is long, I should factorize it but for now here it is. Comments and explanation are coming just after !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Everything else to launch the optimization.\n",
    "    \n",
    "    \"\"\"\n",
    "    pareto = tools.ParetoFront()\n",
    "\n",
    "    pop = toolbox.population(n=MU)\n",
    "    graph = []\n",
    "    data = []\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "    data.append(fitnesses)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        graph.append(ind.fitness.values)\n",
    "\n",
    "    # This is just to assign the crowding distance to the individuals\n",
    "    # no actual selection is done\n",
    "    pop = toolbox.select(pop, len(pop))\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, NGEN):\n",
    "        # Vary the population\n",
    "        offspring = tools.selTournamentDCD(pop, len(pop))\n",
    "        offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "\n",
    "        for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() <= CXPB:\n",
    "                ind1, ind2 = crossover(ind1, ind2)\n",
    "\n",
    "            toolbox.mutate(ind1)\n",
    "            toolbox.mutate(ind2)\n",
    "            del ind1.fitness.values, ind2.fitness.values\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        data.append(fitnesses)\n",
    "        monitoring(data)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            graph.append(ind.fitness.values)\n",
    "\n",
    "        # Select the next generation population\n",
    "        pop = toolbox.select(pop + offspring, MU)\n",
    "\n",
    "    pareto.update(pop)\n",
    "\n",
    "    return pop, pareto, graph, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of code lines here, but not much really hard to understand.\n",
    "\n",
    "On the first line, a Pareto object is created to store individuals that belong to the first order front. Then 6 lines of code enable to check wether the fitness associated with each individual is valid and if not to evaluate the individual and attribute the fitness.\n",
    "\n",
    "Then the algorithm selects each pair of individual in the order and mutate them and do some crossover after comparing them and selecting the best one.\n",
    "\n",
    "The code is not that DEAP specific and is self-sufficient for the rest of the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation function\n",
    "This is wrong, but here is a way to test the code: I created a fast computing random evaluation function. It works but there will no evolutionary process involved as the function is not consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ind):\n",
    "    \"\"\"\n",
    "    Returns random values to the optimisation to speed up tests\n",
    "    \"\"\"\n",
    "    objective1 = random.randint(10,1000)\n",
    "    objective2 = random.randint(10,50)\n",
    "    objective3 = random.randint(200,500)\n",
    "    \n",
    "    return objective1, objective2, objective3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please replace that with the evaluation function you want ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last but not least: let's launch it\n",
    "I did set it to do multiprocessing for the example, mainly to show that it was integrated in a toolbox in DEAP: thanks to the developers for making it so easy !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #    Multiprocessing pool: I want to compute faster\n",
    "    pool = multiprocessing.Pool()\n",
    "    toolbox.register(\"map\", pool.map)\n",
    "\n",
    "    init_opti()\n",
    "    pop, optimal_front, graph_data, data = main()\n",
    "\n",
    "    # Saving the Pareto Front, for further exploitation\n",
    "    with open('./pareto_front.txt', 'w') as front:\n",
    "        for line in optimal_front.items:\n",
    "            front.write(str(line) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is made to launch the optimization and write down the pareto front for further exploitation. There is still other variables that are not exploited: it actually depends on what is the plan after the application of multi-objective optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This is still in progress but here is a quick way to launch and understand a bit better how the library DEAP works.\n",
    "Do ask for further details as I would like to update this notebook with technical points that are a bit tricky to understand.\n",
    "\n",
    "\n",
    "## References\n",
    "Deb, Kalyanmoy, Amrit Pratap, Sameer Agarwal, and T. Meyarivan. 2002. “A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II.” IEEE Transactions on Evolutionary Computation 6 (2): 182–97. https://doi.org/10.1109/4235.996017.\n",
    "\n",
    "Fortin, Félix-Antoine, François-Michel De Rainville, Marc-André Gardner, Marc Parizeau, and Christian Gagné. 2012. “DEAP : Evolutionary Algorithms Made Easy.” Journal of Machine Learning Research 13: 2171–75. https://doi.org/10.1.1.413.6512.\n",
    "\n",
    "Fortin, Félix-Antoine, and Marc Parizeau. 2013. “Revisiting the NSGA-II Crowding-Distance Computation.” Proceeding of the Fifteenth Annual Conference on Genetic and Evolutionary Computation Conference - GECCO ’13, 623. https://doi.org/10.1145/2463372.2463456."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
